{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd, create_mobilenetv1_ssd_predictor\n",
    "from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite, create_mobilenetv1_ssd_lite_predictor\n",
    "from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite, create_squeezenet_ssd_lite_predictor\n",
    "from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite, create_mobilenetv2_ssd_lite_predictor\n",
    "from vision.utils.misc import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv2.imread(\"image/1.jpg\")\n",
    "img_2 = cv2.imread(\"image/2.jpg\")\n",
    "img_3 = cv2.imread(\"image/3.jpg\")\n",
    "img_4 = cv2.imread(\"image/4.jpg\")\n",
    "img_5 = cv2.imread(\"image/5.jpg\")\n",
    "img_6 = cv2.imread(\"image/6.jpg\")\n",
    "img_7 = cv2.imread(\"image/7.jpg\")\n",
    "img_8 = cv2.imread(\"image/8.jpg\")\n",
    "img_9 = cv2.imread(\"image/9.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img1, img2, img3, img4 = None):\n",
    "    fig = plt.figure(num=None, figsize=(8, 8), dpi=100, facecolor='w', edgecolor='k')\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(num=None, figsize=(6, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "    plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    if img4 is not None:\n",
    "        plt.figure(num=None, figsize=(6, 6), dpi=100, facecolor='w', edgecolor='k')\n",
    "        plt.imshow(cv2.cvtColor(img4, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"models/voc-model-labels.txt\"\n",
    "model_path = \"models/mobilenet-v1-ssd-mp-0_675.pth\"\n",
    "\n",
    "# label_path = \"models/voc-model-labels.txt\"\n",
    "# model_path = \"models/mb2-ssd-lite-mp-0_686.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "num_classes = len(class_names)\n",
    "\n",
    "net = create_mobilenetv1_ssd(len(class_names), is_test=True)\n",
    "predictor = create_mobilenetv1_ssd_predictor(net, candidate_size=200)\n",
    "\n",
    "# net = create_mobilenetv2_ssd_lite(len(class_names), is_test=True)\n",
    "# predictor = create_mobilenetv2_ssd_lite_predictor(net, candidate_size=200)\n",
    "\n",
    "net.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera2global(M, p):\n",
    "    if len(p) == 2:\n",
    "        p.append(1.)\n",
    "    return np.matmul(M, p).astype(int)\n",
    "def global2camera(M, p):\n",
    "    if len(p) == 2:\n",
    "        p.append(1.)\n",
    "    return np.matmul(np.linalg.inv(M), p).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.float32([[1100.,  151.],\n",
    "       [ 335.,  951.],\n",
    "       [1669.,  954.],\n",
    "       [1884.,  156.]])\n",
    "\n",
    "pts2 = np.float32([[ 624.,   82.],\n",
    "       [ 619.,  997.],\n",
    "       [1518.,  969.],\n",
    "       [1530.,   43.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = [(0, 180, 270), (255, 180, 0), (100, 170, 100)\n",
    "            , (50, 255, 0), (0, 255, 30), (100, 30, 250)\n",
    "            , (20, 90, 250), (200, 0, 20), (200, 200, 30)\n",
    "            , (200, 30, 30), (200, 200, 20), (100, 30, 250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture('video/normal_night.mp4')\n",
    "# ret, frame = cap.read()\n",
    "# pts1 = []\n",
    "# pts2 = []\n",
    "# count = [0]\n",
    "# def click_Mouse(event, x, y, flags, param):\n",
    "#     global click_p\n",
    "#     if event == cv2.EVENT_LBUTTONUP:\n",
    "#         if count[0] < 4:\n",
    "#             pts1.append([x, y])\n",
    "#         else:\n",
    "#             pts2.append([x, y])\n",
    "#         count[0] += 1\n",
    "\n",
    "# cv2.namedWindow(\"vector\", 0)\n",
    "# cv2.resizeWindow(\"vector\", 750, 750);\n",
    "# cv2.setMouseCallback(\"vector\", click_Mouse)\n",
    "# cv2.imshow(\"vector\", frame)\n",
    "# # ch = cv2.waitKey(1)\n",
    "# # if ch & 0xFF == ord('q'):\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows() \n",
    "# pts1 = np.float32(pts1) \n",
    "# pts2 = np.float32(pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video1 = 'video/wind_rain.mp4'\n",
    "video2 = 'video/normal_night.mp4'\n",
    "video3 = 'video/dark.mp4'\n",
    "video4 = 'video/622.mp4'\n",
    "cam = 0   # capture from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(mu, sigma2, x):\n",
    "    coefficient = 1.0/math.sqrt(2.0 * math.pi * sigma2)\n",
    "    exponential = exp(-0.5 * (x-mu) ** 2 / sigma2)\n",
    "    return coefficient * exponential\n",
    "def update(mean1, var1, mean2, var2):\n",
    "    new_mean = (var2 * mean1 + var1*mean2) / (var2 + var1)\n",
    "    new_var = 1/(1/var2 + 1/var1)\n",
    "    return [new_mean, new_var]\n",
    "def predict(mean1, var1, mean2, var2):\n",
    "    new_mean = mean1 + mean2\n",
    "    new_var = var1 + var2\n",
    "    return [new_mean, new_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img1, path):\n",
    "    fig = plt.figure(num=None, figsize=(10, 10), dpi=200, facecolor='w', edgecolor='k')\n",
    "\n",
    "    fig.add_subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    fig.add_subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(path, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obj(object):\n",
    "    def __init__(self, pose, idx=-1, idleness=0):\n",
    "        self.idleness = idleness\n",
    "        self.idx = idx\n",
    "        self.category = \"\"\n",
    "        self.pose = pose\n",
    "        self.path = [pose]\n",
    "        self.alert_cnt = 0\n",
    "        \n",
    "    def get_idx(self):\n",
    "        return self.idx\n",
    "    \n",
    "    def get_category(self):\n",
    "        return self.category\n",
    "    \n",
    "    def get_idleness(self):\n",
    "        return self.idleness\n",
    "    \n",
    "    def get_pose(self):\n",
    "        return self.pose\n",
    "    \n",
    "    def get_alert_cnt(self):\n",
    "        return self.alert_cnt\n",
    "    \n",
    "    def set_idx(self, idx):\n",
    "        self.idx = idx\n",
    "    \n",
    "    def set_pose(self, pose):\n",
    "        self.pose = pose\n",
    "        self.path.append(pose)\n",
    "        \n",
    "    def reset_idleness(self):\n",
    "        self.idleness = 0\n",
    "    \n",
    "    def add_idleness(self, num):\n",
    "        self.idleness = self.idleness + num\n",
    "        \n",
    "    def reset_alert_cnt(self):\n",
    "        self.alert_cnt = 0\n",
    "    \n",
    "    def add_alert_cnt(self, num):\n",
    "        self.alert_cnt = self.alert_cnt + num\n",
    "    \n",
    "    def add_path(self, pose):\n",
    "        self.path.append(pose)\n",
    "    \n",
    "    def get_path(self, idx=None):\n",
    "        if idx is None:\n",
    "            return self.path\n",
    "        else:\n",
    "            return self.path[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1, p2):\n",
    "    return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.813847515295 1.689720400665629\n"
     ]
    }
   ],
   "source": [
    "def limit_rad(rad):\n",
    "    if rad > np.pi:\n",
    "        return limit_rad(rad - 2.*np.pi)\n",
    "    elif rad < -np.pi:\n",
    "        return limit_rad(rad + 2.*np.pi)\n",
    "    else:\n",
    "        return rad\n",
    "    \n",
    "def check_direction(rad, shift):\n",
    "    rad = limit_rad(rad + np.pi/2. - shift)\n",
    "    if rad > np.pi/4. and rad < 3.*np.pi/4.:\n",
    "        return 1\n",
    "    elif rad < -np.pi/4. and rad > -3.*np.pi/4.: \n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def click_Mouse(event, x, y, flags, param):\n",
    "    global click_p\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        click_p = [[x, y]]\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        click_p.append([x, y])\n",
    "        fy = click_p[1][1] - click_p[0][1]\n",
    "        fx = click_p[1][0] - click_p[0][0]\n",
    "        rad = np.arctan2(fy, fx)\n",
    "        shift = np.radians(90.)\n",
    "        direct = check_direction(rad, shift)\n",
    "        print(np.degrees(rad), rad)\n",
    "\n",
    "cv2.namedWindow(\"vector\", 0)\n",
    "cv2.resizeWindow(\"vector\", 750, 750);\n",
    "cv2.setMouseCallback(\"vector\", click_Mouse)\n",
    "cv2.imshow(\"vector\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp = False\n",
    "src = video2\n",
    "cap = cv2.VideoCapture(src)\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "M_shift = np.eye(3)\n",
    "M_shift[0,2] = 942.48 # x\n",
    "M_shift[1,2] = 383 # y\n",
    "M_ = np.matmul(M_shift, M)\n",
    "ret, frame = cap.read()\n",
    "if warp:\n",
    "    frame = cv2.warpPerspective(frame, M_,(frame.shape[1]+942, frame.shape[0]+383))\n",
    "img_shape = frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "14\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "10\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "SHIFT = 1.5639937106400879\n",
    "cap = cv2.VideoCapture(src)\n",
    "cv2.namedWindow(\"frame\",0);\n",
    "cv2.resizeWindow(\"frame\", 750, 750);\n",
    "cv2.namedWindow(\"path\",0);\n",
    "cv2.resizeWindow(\"path\", 750, 750);\n",
    "path = np.zeros((img_shape[0], img_shape[1], 3), np.uint8)\n",
    "obj_list = []\n",
    "idx_count = -1\n",
    "alert = False\n",
    "DIS_THRESH = 300\n",
    "MOVE_THRESH = 3\n",
    "while(cap.isOpened()):\n",
    "    alert = False\n",
    "    ret, frame = cap.read()\n",
    "    if frame is not None:\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        boxes, labels, probs = predictor.predict(image, 10, 0.35)\n",
    "        boxes = boxes.numpy().astype(int)\n",
    "        detections = []\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i, :]\n",
    "            label = f\"{class_names[labels[i]]}: {probs[i]:.2f}\"\n",
    "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (255, 255, 0), 4)\n",
    "            if warp:\n",
    "                center = camera2global(M_, [(box[0]+box[2])/2, (box[1]+box[3])/2])\n",
    "            else:\n",
    "                center = [int((box[0]+box[2])/2), int((box[1]+box[3])/2)]\n",
    "            obj = Obj(center[:2], i, 0)\n",
    "            detections.append(obj)\n",
    "            \n",
    "            cv2.putText(frame, label,\n",
    "                        (box[0]+20, box[1]+40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,  # font scale\n",
    "                        (255, 0, 255),\n",
    "                        2)  # line type\n",
    "    \n",
    "        # Tracking Algorithm\n",
    "        choose_detection_list = []\n",
    "        for obj in obj_list:\n",
    "            closest_detection_idx = -1\n",
    "            min_dis = 1000000\n",
    "            for detection in detections:\n",
    "                if detection.get_idx() in choose_detection_list:\n",
    "                    continue\n",
    "                dis = distance(obj.get_pose(), detection.get_pose())\n",
    "                if dis < DIS_THRESH and dis < min_dis:\n",
    "                    closest_detection_idx = detection.get_idx()\n",
    "                    min_dis = dis\n",
    "            # keep tracking certain object\n",
    "            if closest_detection_idx != -1:\n",
    "                choose_detection_list.append(closest_detection_idx)\n",
    "                obj.set_pose(detections[closest_detection_idx].get_pose())\n",
    "                obj.reset_idleness()\n",
    "                p1 = obj.get_path(-2)\n",
    "                p2 = obj.get_path(-1)\n",
    "                fx = p2[0] - p1[0]\n",
    "                fy = p2[1] - p1[1]\n",
    "                ang = np.arctan2(fy, fx)\n",
    "                v = np.sqrt(fx * fx + fy * fy)\n",
    "                if check_direction(ang, SHIFT) and v > MOVE_THRESH:\n",
    "                    obj.add_alert_cnt(1)\n",
    "                else:\n",
    "                    obj.add_alert_cnt(-1)\n",
    "            else:\n",
    "                obj.add_idleness(1)\n",
    "                \n",
    "        for detection in detections:\n",
    "            if detection.get_idx() not in choose_detection_list:\n",
    "                idx_count += 1\n",
    "                detection.set_idx(idx_count)\n",
    "                obj_list.append(detection)\n",
    "                \n",
    "        temp_obj_list = []\n",
    "        for obj in obj_list:\n",
    "            if obj.get_idleness() < 3:\n",
    "                temp_obj_list.append(obj)\n",
    "                if obj.get_alert_cnt() > 3:\n",
    "                    print(obj.get_alert_cnt())\n",
    "                    alert = True\n",
    "                    cv2.circle(path, tuple(obj.get_pose()), 15, (255, 255, 255), -1)\n",
    "                else:\n",
    "                    cv2.circle(path, tuple(obj.get_pose()), 15, color_map[obj.get_idx()%9], -1)\n",
    "                \n",
    "        obj_list = temp_obj_list.copy()\n",
    "        if warp:\n",
    "            frame = cv2.warpPerspective(frame, M_,(frame.shape[1]+942, frame.shape[0]+383))\n",
    "        if alert:\n",
    "            cv2.rectangle(frame, (0, 0), (img_shape[1]-1, img_shape[0]-1), (0, 0, 255), 50)\n",
    "        else:\n",
    "            cv2.rectangle(frame, (0, 0), (img_shape[1]-1, img_shape[0]-1), (0, 255, 0), 50)\n",
    "        cv2.imshow('frame',frame)\n",
    "        cv2.imshow('path',path)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create capture object\n",
    "cap = cv2.VideoCapture(5) # Flush the stream\n",
    "\n",
    "#cap = cv2.VideoCapture(1) # Then start the webcam\n",
    "# cap = cv2.VideoCapture('video/wind_rain.mp4')\n",
    "cap = cv2.VideoCapture('video/normal_night.mp4')\n",
    "# cap = cv2.VideoCapture('video/dark.mp4')\n",
    "# cap = cv2.VideoCapture('video/622.mp4')\n",
    "# cap = cv2.VideoCapture(0)   # capture from camera\n",
    "# cap.set(3, 1920)\n",
    "# cap.set(4, 1080)\n",
    "\n",
    "cv2.namedWindow(\"frame\",0);\n",
    "cv2.resizeWindow(\"frame\", 750, 750);\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "M_shift = np.eye(3)\n",
    "M_shift[0,2] = 942.48 # x\n",
    "M_shift[1,2] = 383 # y\n",
    "M_ = np.matmul(M_shift, M)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if (frame is not None):\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        boxes, labels, probs = predictor.predict(image, 10, 0.25)\n",
    "        for i in range(boxes.size(0)):\n",
    "            box = boxes[i, :]\n",
    "            label = f\"{class_names[labels[i]]}: {probs[i]:.2f}\"\n",
    "            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (255, 255, 0), 4)\n",
    "\n",
    "            cv2.putText(frame, label,\n",
    "                        (box[0]+20, box[1]+40),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        1,  # font scale\n",
    "                        (255, 0, 255),\n",
    "                        2)  # line type\n",
    "            x = [125, 169]\n",
    "            y = [100, 124]\n",
    "            plt.plot(x, y)\n",
    "        \n",
    "\n",
    "#         frame = cv2.warpPerspective(frame, M_,(frame.shape[1]+942, frame.shape[0]+383))\n",
    "#         frame = cv2.warpPerspective(frame, M,(frame.shape[1], frame.shape[0]))\n",
    "#         frame = cv2.warpPerspective(frame, M_,(frame.shape[1], frame.shape[0]))\n",
    "        cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_x = 1000\n",
    "min_y = 1000\n",
    "max_x = -1000\n",
    "max_y = -1000\n",
    "for i in range(frame.shape[0]): # y\n",
    "    for j in range(frame.shape[1]): # x\n",
    "        p = np.matmul(M, [j, i, 1])\n",
    "        min_x = min(min_x, p[0])\n",
    "        min_y = min(min_y, p[1])\n",
    "        max_x = max(max_x, p[0])\n",
    "        max_y = max(max_y, p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.array([frame.shape[1]-1, frame.shape[0]-1, 1])\n",
    "p2 = np.array([frame.shape[1]-1, 0, 1])\n",
    "p3 = np.array([0, frame.shape[0]-1, 1])\n",
    "p4 = np.array([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2g(M, p4)\n",
    "g2c(M, c2g(M, p4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-275.83737774,  302.7795715 ,    1.20523873])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.matmul(M, [220, 219, 1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([220., 219.,   1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.linalg.inv(M), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-942.4806114538623 -383.0608913082446 5570.814650645365 3053.9478925008257\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b106c6a484f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(min_x, min_y, max_x, max_y)\n",
    "print(frame.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
